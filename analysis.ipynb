{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad684cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import re\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style untuk plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fff66058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi helper untuk basic info\n",
    "def basic_info(df, filename):\n",
    "    print(f\"\\nüìä {filename}\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    print(f\"Data types:\\n{df.dtypes}\")\n",
    "    print(f\"Missing values:\\n{df.isnull().sum()}\")\n",
    "    print(f\"Memory usage: {df.memory_usage().sum() / 1024:.2f} KB\")\n",
    "    return df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50d720c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "file_names = {\n",
    "    'absensi': 'MineToday Dataset/train/train_absensi.csv',\n",
    "    'mini_project': 'MineToday Dataset/train/train_mini_project.csv', \n",
    "    'pendaftaran': 'MineToday Dataset/train/train_pendaftaran.csv',\n",
    "    'pretest_ml': 'MineToday Dataset/train/train_pretest_ml.csv',\n",
    "    'pretest_py': 'MineToday Dataset/train/train_pretest_py.csv',\n",
    "    'pretest_st': 'MineToday Dataset/train/train_pretest_st.csv',\n",
    "    'weekly_quiz': 'MineToday Dataset/train/train_weekly_quiz.csv'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a62d18bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets():\n",
    "    datasets = {}\n",
    "    for name, path in file_names.items():\n",
    "        try:\n",
    "            datasets[name] = pd.read_csv(path)\n",
    "            print(f\"‚úÖ {name}: {datasets[name].shape}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"‚ùå {name}: File not found at {path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå {name}: Error loading - {e}\")\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77e16e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisis detail setiap dataset\n",
    "for file_name, df in datasets.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    sample_data = basic_info(df, file_name)\n",
    "    print(f\"\\nSample data (first 3 rows):\")\n",
    "    print(sample_data.head(3))\n",
    "    \n",
    "    # Cek unique values untuk kolom kategorikal\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    if len(categorical_cols) > 0:\n",
    "        print(f\"\\nüè∑Ô∏è  Categorical columns unique values:\")\n",
    "        for col in categorical_cols[:5]:  # Limit to first 5 columns\n",
    "            unique_vals = df[col].nunique()\n",
    "            print(f\"  {col}: {unique_vals} unique values\")\n",
    "            if unique_vals <= 10:\n",
    "                print(f\"    Values: {df[col].unique()[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41c1f09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üîó PARTICIPANT ID ANALYSIS\n",
      "----------------------------------------\n",
      "Potential ID columns:\n"
     ]
    }
   ],
   "source": [
    "# Analisis ID peserta untuk join datasets\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"üîó PARTICIPANT ID ANALYSIS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Cari kolom yang mungkin berisi ID peserta\n",
    "id_candidates = []\n",
    "for file_name, df in datasets.items():\n",
    "    for col in df.columns:\n",
    "        if any(keyword in col.lower() for keyword in ['id', 'email', 'nama', 'timestamp']):\n",
    "            id_candidates.append((file_name, col, df[col].nunique()))\n",
    "\n",
    "print(\"Potential ID columns:\")\n",
    "for file_name, col, unique_count in id_candidates:\n",
    "    print(f\"  {file_name}: {col} ({unique_count} unique values)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc32789d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è∞ TIMESTAMP ANALYSIS\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Cek timestamp patterns\n",
    "print(f\"\\n‚è∞ TIMESTAMP ANALYSIS\")\n",
    "print(\"-\" * 40)\n",
    "for file_name, df in datasets.items():\n",
    "    timestamp_cols = [col for col in df.columns if 'timestamp' in col.lower() or 'tanggal' in col.lower()]\n",
    "    if timestamp_cols:\n",
    "        print(f\"\\n{file_name}:\")\n",
    "        for col in timestamp_cols:\n",
    "            print(f\"  {col}: {df[col].dtype}\")\n",
    "            print(f\"    Sample: {df[col].dropna().head(2).tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a598903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìä NUMERICAL COLUMNS SUMMARY\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Summary statistics untuk numerical columns\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"üìä NUMERICAL COLUMNS SUMMARY\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for file_name, df in datasets.items():\n",
    "    numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    if len(numerical_cols) > 0:\n",
    "        print(f\"\\n{file_name}:\")\n",
    "        print(df[numerical_cols].describe().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6027d17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üéØ POTENTIAL TARGET PATTERNS\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Pattern analysis untuk potential target creation\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"üéØ POTENTIAL TARGET PATTERNS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Analisis completion patterns\n",
    "completion_indicators = []\n",
    "for file_name, df in datasets.items():\n",
    "    if 'absensi' in file_name:\n",
    "        print(f\"\\n{file_name}:\")\n",
    "        if 'Pertemuan ke' in df.columns or 'Pertemuan ke-' in df.columns:\n",
    "            pertemuan_col = 'Pertemuan ke' if 'Pertemuan ke' in df.columns else 'Pertemuan ke-'\n",
    "            print(f\"  Column: {pertemuan_col}\")\n",
    "            print(f\"  Data type: {df[pertemuan_col].dtype}\")\n",
    "            print(f\"  Unique values: {sorted(df[pertemuan_col].dropna().unique())}\")\n",
    "            print(f\"  Missing values: {df[pertemuan_col].isnull().sum()}\")\n",
    "            \n",
    "            # Convert to numeric untuk cari max\n",
    "            try:\n",
    "                numeric_values = pd.to_numeric(df[pertemuan_col], errors='coerce')\n",
    "                max_pertemuan = numeric_values.max()\n",
    "                print(f\"  Max pertemuan: {max_pertemuan}\")\n",
    "                print(f\"  Min pertemuan: {numeric_values.min()}\")\n",
    "                print(f\"  Total attendances: {len(df)}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  Error processing pertemuan: {e}\")\n",
    "            \n",
    "    elif 'quiz' in file_name:\n",
    "        print(f\"\\n{file_name}:\")\n",
    "        print(f\"  Total quiz records: {df.shape[0]}\")\n",
    "        # Cek jika ada kolom score/nilai\n",
    "        score_cols = [col for col in df.columns if any(keyword in col.lower() for keyword in ['score', 'nilai', 'point'])]\n",
    "        if score_cols:\n",
    "            for col in score_cols[:3]:  # Limit to first 3 score columns\n",
    "                print(f\"  {col}: mean={df[col].mean():.2f}, std={df[col].std():.2f}\")\n",
    "        \n",
    "    elif 'mini_project' in file_name:\n",
    "        print(f\"\\n{file_name}:\")\n",
    "        print(f\"  Total project submissions: {df.shape[0]}\")\n",
    "        # Cek jika ada link submissions\n",
    "        link_cols = [col for col in df.columns if 'link' in col.lower() or 'url' in col.lower()]\n",
    "        if link_cols:\n",
    "            for col in link_cols:\n",
    "                non_empty = df[col].dropna().shape[0]\n",
    "                print(f\"  {col}: {non_empty} non-empty submissions\")\n",
    "        \n",
    "    elif 'pretest' in file_name:\n",
    "        test_type = file_name.split('_')[-1].replace('.csv', '').upper()\n",
    "        print(f\"\\n{file_name}:\")\n",
    "        print(f\"  Pretest {test_type} participants: {df.shape[0]}\")\n",
    "        # Cek score columns\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        if len(numeric_cols) > 0:\n",
    "            for col in numeric_cols[:3]:  # First 3 numeric columns\n",
    "                print(f\"  {col}: mean={df[col].mean():.2f}, range=[{df[col].min():.1f}, {df[col].max():.1f}]\")\n",
    "    \n",
    "    elif 'pendaftaran' in file_name:\n",
    "        print(f\"\\n{file_name}:\")\n",
    "        print(f\"  Total registrations: {df.shape[0]}\")\n",
    "        if 'Status' in df.columns:\n",
    "            status_counts = df['Status'].value_counts()\n",
    "            print(f\"  Status distribution: {dict(status_counts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91b92e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà CROSS-DATASET ANALYSIS\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nüìà CROSS-DATASET ANALYSIS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Coba identifikasi common participants\n",
    "participant_counts = {}\n",
    "for file_name, df in datasets.items():\n",
    "    # Cari kolom yang mungkin identifier\n",
    "    for col in df.columns:\n",
    "        if 'email' in col.lower() or 'nama' in col.lower():\n",
    "            unique_participants = df[col].nunique()\n",
    "            participant_counts[f\"{file_name}_{col}\"] = unique_participants\n",
    "            print(f\"{file_name} - {col}: {unique_participants} unique participants\")\n",
    "\n",
    "if participant_counts:\n",
    "    print(f\"\\nParticipant overlap analysis needed for joining datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18a506be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ DATA INTEGRATION\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"üîÑ DATA INTEGRATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "def parse_score(score_str):\n",
    "    \"\"\"Convert '80 / 100' to 0.8\"\"\"\n",
    "    if pd.isna(score_str):\n",
    "        return np.nan\n",
    "    if isinstance(score_str, str) and '/' in score_str:\n",
    "        try:\n",
    "            num, den = score_str.split('/')\n",
    "            return float(num.strip()) / float(den.strip())\n",
    "        except:\n",
    "            return np.nan\n",
    "    return score_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d1b2025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_meeting_number(meeting_str):\n",
    "    \"\"\"Extract number from 'Pertemuan 12'\"\"\"\n",
    "    if pd.isna(meeting_str):\n",
    "        return np.nan\n",
    "    if isinstance(meeting_str, str):\n",
    "        match = re.search(r'\\d+', meeting_str)\n",
    "        return int(match.group()) if match else np.nan\n",
    "    return meeting_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a449af0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üõ†Ô∏è FEATURE ENGINEERING\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"üõ†Ô∏è FEATURE ENGINEERING\")\n",
    "print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d884f8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_attendance_features(df_absensi):\n",
    "    print(\"\\nüìä Processing Attendance Data...\")\n",
    "    \n",
    "    # Parse meeting numbers dari 'Pertemuan ke' column\n",
    "    df_absensi['meeting_num'] = df_absensi['Pertemuan ke'].apply(extract_meeting_number)\n",
    "    \n",
    "    # Aggregate per participant\n",
    "    attendance_stats = df_absensi.groupby('id').agg({\n",
    "        'meeting_num': ['count', 'max', 'min'],\n",
    "        'Kualitas materi ': 'mean',\n",
    "        'Kualitas trainer ': 'mean'\n",
    "    }).round(3)\n",
    "    \n",
    "    # Flatten column names\n",
    "    attendance_stats.columns = [\n",
    "        'total_meetings_attended', 'highest_meeting', 'first_meeting',\n",
    "        'avg_material_quality', 'avg_trainer_quality'\n",
    "    ]\n",
    "    \n",
    "    # Calculate key metrics\n",
    "    MAX_MEETINGS = 30  # Assuming 30 total meetings\n",
    "    attendance_stats['attendance_rate'] = (\n",
    "        attendance_stats['total_meetings_attended'] / MAX_MEETINGS\n",
    "    ).clip(0, 1).round(3)\n",
    "    \n",
    "    # Engagement score (high attendance + good ratings)\n",
    "    attendance_stats['engagement_score'] = (\n",
    "        attendance_stats['attendance_rate'] * 0.6 + \n",
    "        (attendance_stats['avg_material_quality'] / 5) * 0.2 +\n",
    "        (attendance_stats['avg_trainer_quality'] / 5) * 0.2\n",
    "    ).round(3)\n",
    "    \n",
    "    return attendance_stats.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebb3eb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_assessment_features(datasets):\n",
    "    print(\"\\nüìä Processing Assessment Scores...\")\n",
    "    \n",
    "    assessment_features = []\n",
    "    \n",
    "    # Process each pretest\n",
    "    for test_name in ['pretest_ml', 'pretest_py', 'pretest_st']:\n",
    "        df = datasets[test_name].copy()\n",
    "        \n",
    "        # Parse scores\n",
    "        df['score_normalized'] = df['Score'].apply(parse_score)\n",
    "        \n",
    "        # Get best attempt per participant\n",
    "        best_scores = df.groupby('id')['score_normalized'].max().reset_index()\n",
    "        best_scores.columns = ['id', f'{test_name}_best_score']\n",
    "        \n",
    "        assessment_features.append(best_scores)\n",
    "    \n",
    "    # Merge all assessment scores\n",
    "    combined_assessments = assessment_features[0]\n",
    "    for df in assessment_features[1:]:\n",
    "        combined_assessments = combined_assessments.merge(df, on='id', how='outer')\n",
    "    \n",
    "    # Calculate aggregate metrics\n",
    "    score_cols = ['pretest_ml_best_score', 'pretest_py_best_score', 'pretest_st_best_score']\n",
    "    \n",
    "    combined_assessments['avg_pretest_score'] = (\n",
    "        combined_assessments[score_cols].mean(axis=1, skipna=True).round(3)\n",
    "    )\n",
    "    \n",
    "    combined_assessments['assessment_completion_rate'] = (\n",
    "        combined_assessments[score_cols].notna().sum(axis=1) / len(score_cols)\n",
    "    ).round(3)\n",
    "    \n",
    "    # Performance category\n",
    "    combined_assessments['performance_level'] = pd.cut(\n",
    "        combined_assessments['avg_pretest_score'], \n",
    "        bins=[0, 0.5, 0.7, 0.85, 1.0], \n",
    "        labels=['Low', 'Medium', 'High', 'Excellent']\n",
    "    )\n",
    "    \n",
    "    return combined_assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2e61143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission_features(datasets):\n",
    "    print(\"\\nüìä Processing Submission Data...\")\n",
    "    \n",
    "    submission_data = []\n",
    "    \n",
    "    # Mini project submissions\n",
    "    mini_project = datasets['mini_project'].groupby('id').size().reset_index()\n",
    "    mini_project.columns = ['id', 'mini_project_count']\n",
    "    mini_project['has_mini_project'] = (mini_project['mini_project_count'] > 0).astype(int)\n",
    "    submission_data.append(mini_project[['id', 'has_mini_project']])\n",
    "    \n",
    "    # Weekly quiz submissions\n",
    "    weekly_quiz = datasets['weekly_quiz'].groupby('id').size().reset_index()\n",
    "    weekly_quiz.columns = ['id', 'quiz_submissions']\n",
    "    weekly_quiz['has_weekly_quiz'] = (weekly_quiz['quiz_submissions'] > 0).astype(int)\n",
    "    submission_data.append(weekly_quiz[['id', 'has_weekly_quiz']])\n",
    "    \n",
    "    # Combine submission features\n",
    "    combined_submissions = submission_data[0]\n",
    "    for df in submission_data[1:]:\n",
    "        combined_submissions = combined_submissions.merge(df, on='id', how='outer')\n",
    "    \n",
    "    # Fill missing values\n",
    "    combined_submissions = combined_submissions.fillna(0)\n",
    "    \n",
    "    # Overall submission rate\n",
    "    combined_submissions['total_submissions'] = (\n",
    "        combined_submissions['has_mini_project'] + \n",
    "        combined_submissions['has_weekly_quiz']\n",
    "    )\n",
    "    \n",
    "    return combined_submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09f8f390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_registration_features(df_registration):\n",
    "    print(\"\\nüìä Processing Registration Data...\")\n",
    "    \n",
    "    reg_features = df_registration[['id', 'Status', 'Pilihan Jadwal Kelas']].copy()\n",
    "    \n",
    "    # Encode status\n",
    "    status_mapping = {\n",
    "        'Mahasiswa': 1, 'Fresh Graduates': 2, \n",
    "        'Pekerja aktif': 3, 'Umum': 4\n",
    "    }\n",
    "    reg_features['status_encoded'] = reg_features['Status'].map(status_mapping)\n",
    "    \n",
    "    # Extract batch info\n",
    "    reg_features['batch'] = reg_features['Pilihan Jadwal Kelas'].str.extract(r'Batch (\\d+)')\n",
    "    reg_features['batch'] = pd.to_numeric(reg_features['batch'], errors='coerce')\n",
    "    \n",
    "    return reg_features[['id', 'status_encoded', 'batch']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5c8bacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ absensi: (11714, 12)\n",
      "‚úÖ mini_project: (468, 5)\n",
      "‚úÖ pendaftaran: (492, 9)\n",
      "‚úÖ pretest_ml: (502, 14)\n",
      "‚úÖ pretest_py: (544, 14)\n",
      "‚úÖ pretest_st: (500, 19)\n",
      "‚úÖ weekly_quiz: (487, 5)\n",
      "\n",
      "üìã Unique participants per dataset:\n",
      "  absensi: 509 unique IDs\n",
      "  mini_project: 468 unique IDs\n",
      "  pendaftaran: 492 unique IDs\n",
      "  pretest_ml: 494 unique IDs\n",
      "  pretest_py: 526 unique IDs\n",
      "  pretest_st: 497 unique IDs\n",
      "  weekly_quiz: 483 unique IDs\n",
      "\n",
      "üë• Total unique participants across all datasets: 549\n",
      "‚úÖ Master participant table created with 549 participants\n",
      "\n",
      "üìä Processing Attendance Data...\n",
      "\n",
      "üìä Processing Assessment Scores...\n",
      "\n",
      "üìä Processing Submission Data...\n",
      "\n",
      "üìä Processing Registration Data...\n"
     ]
    }
   ],
   "source": [
    "# Execute feature engineering\n",
    "datasets = load_datasets()\n",
    "\n",
    "# Get all unique participant IDs (missing from script 1)\n",
    "print(f\"\\nüìã Unique participants per dataset:\")\n",
    "all_participant_ids = set()\n",
    "for name, df in datasets.items():\n",
    "    unique_ids = df['id'].nunique()\n",
    "    print(f\"  {name}: {unique_ids} unique IDs\")\n",
    "    all_participant_ids.update(df['id'].unique())\n",
    "\n",
    "print(f\"\\nüë• Total unique participants across all datasets: {len(all_participant_ids)}\")\n",
    "\n",
    "# Create master participant table\n",
    "master_df = pd.DataFrame({'id': list(all_participant_ids)})\n",
    "print(f\"‚úÖ Master participant table created with {len(master_df)} participants\")\n",
    "\n",
    "attendance_features = create_attendance_features(datasets['absensi'])\n",
    "assessment_features = create_assessment_features(datasets)\n",
    "submission_features = create_submission_features(datasets)\n",
    "registration_features = create_registration_features(datasets['pendaftaran'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7e37ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Merging all features...\n",
      "  ‚úÖ Merged attendance: 549 ‚Üí 549 rows\n",
      "  ‚úÖ Merged assessment: 549 ‚Üí 549 rows\n",
      "  ‚úÖ Merged submission: 549 ‚Üí 549 rows\n",
      "  ‚úÖ Merged registration: 549 ‚Üí 549 rows\n",
      "\n",
      "üéØ Final feature matrix: (549, 19)\n",
      "Columns: ['id', 'total_meetings_attended', 'highest_meeting', 'first_meeting', 'avg_material_quality', 'avg_trainer_quality', 'attendance_rate', 'engagement_score', 'pretest_ml_best_score', 'pretest_py_best_score', 'pretest_st_best_score', 'avg_pretest_score', 'assessment_completion_rate', 'performance_level', 'has_mini_project', 'has_weekly_quiz', 'total_submissions', 'status_encoded', 'batch']\n",
      "\n",
      "üìä Sample of engineered features:\n",
      "                                     id  total_meetings_attended  \\\n",
      "0  366c8261-243e-4eab-9695-6df81979597a                     18.0   \n",
      "1  84d29b44-26c6-4b05-8a67-31831d35be32                     28.0   \n",
      "2  e0766991-32fc-4294-b1e2-a0dff52c64f2                     23.0   \n",
      "3  a59fa924-4733-471c-8754-f6595cd0e6f1                     27.0   \n",
      "4  ab9d4c1f-1773-4f12-88e1-ecd78f51e309                     30.0   \n",
      "\n",
      "   highest_meeting  first_meeting  avg_material_quality  avg_trainer_quality  \\\n",
      "0             18.0            1.0                 4.500                4.611   \n",
      "1             28.0            1.0                 4.357                4.536   \n",
      "2             23.0            1.0                 4.522                4.435   \n",
      "3             27.0            1.0                 4.333                4.444   \n",
      "4             30.0            1.0                 4.567                4.433   \n",
      "\n",
      "   attendance_rate  engagement_score  pretest_ml_best_score  \\\n",
      "0            0.600             0.724                    0.5   \n",
      "1            0.933             0.916                    0.8   \n",
      "2            0.767             0.818                    0.5   \n",
      "3            0.900             0.891                    0.5   \n",
      "4            1.000             0.960                    0.8   \n",
      "\n",
      "   pretest_py_best_score  pretest_st_best_score  avg_pretest_score  \\\n",
      "0                    1.0                   0.90              0.800   \n",
      "1                    0.7                   0.85              0.783   \n",
      "2                    0.9                   0.90              0.767   \n",
      "3                    0.7                   0.85              0.683   \n",
      "4                    0.8                   1.00              0.867   \n",
      "\n",
      "   assessment_completion_rate performance_level  has_mini_project  \\\n",
      "0                         1.0              High               1.0   \n",
      "1                         1.0              High               1.0   \n",
      "2                         1.0              High               1.0   \n",
      "3                         1.0            Medium               1.0   \n",
      "4                         1.0         Excellent               1.0   \n",
      "\n",
      "   has_weekly_quiz  total_submissions  status_encoded  batch  \n",
      "0              1.0                2.0             3.0    NaN  \n",
      "1              1.0                2.0             2.0    9.0  \n",
      "2              1.0                2.0             2.0    9.0  \n",
      "3              1.0                2.0             1.0    8.0  \n",
      "4              1.0                2.0             2.0    9.0  \n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nüîÑ Merging all features...\")\n",
    "final_features = master_df.copy()\n",
    "\n",
    "# Merge each feature set\n",
    "feature_sets = [\n",
    "    ('attendance', attendance_features),\n",
    "    ('assessment', assessment_features), \n",
    "    ('submission', submission_features),\n",
    "    ('registration', registration_features)\n",
    "]\n",
    "\n",
    "for name, features in feature_sets:\n",
    "    before_count = len(final_features)\n",
    "    final_features = final_features.merge(features, on='id', how='left')\n",
    "    after_count = len(final_features)\n",
    "    print(f\"  ‚úÖ Merged {name}: {before_count} ‚Üí {after_count} rows\")\n",
    "\n",
    "print(f\"\\nüéØ Final feature matrix: {final_features.shape}\")\n",
    "print(f\"Columns: {list(final_features.columns)}\")\n",
    "\n",
    "# Show sample of final features\n",
    "print(f\"\\nüìä Sample of engineered features:\")\n",
    "print(final_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28c8455e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ TARGET CREATION\n",
      "==================================================\n",
      "\n",
      "üîß Preprocessing for target creation...\n",
      "‚úÖ Target features prepared for 549 participants\n"
     ]
    }
   ],
   "source": [
    "print(\"üéØ TARGET CREATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Fill missing values untuk target creation\n",
    "print(\"\\nüîß Preprocessing for target creation...\")\n",
    "\n",
    "# Select features for target creation\n",
    "target_features = [\n",
    "    'attendance_rate', 'highest_meeting', 'total_meetings_attended',\n",
    "    'avg_pretest_score', 'assessment_completion_rate', \n",
    "    'total_submissions', 'engagement_score'\n",
    "]\n",
    "\n",
    "# Create a subset with target features\n",
    "target_df = final_features[['id'] + target_features].copy()\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "target_df[target_features] = imputer.fit_transform(target_df[target_features])\n",
    "\n",
    "print(f\"‚úÖ Target features prepared for {len(target_df)} participants\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6aa89c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# METHOD 1: RULE-BASED LABELING\n",
    "# ============================================================================\n",
    "\n",
    "def create_rule_based_labels(df):\n",
    "    print(\"\\nüìã Method 1: Rule-Based Labeling\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Define graduation criteria\n",
    "    conditions = {\n",
    "        'high_attendance': df['attendance_rate'] >= 0.75,  # Attended 75%+ meetings\n",
    "        'reached_advanced': df['highest_meeting'] >= 20,   # Reached meeting 20+\n",
    "        'good_performance': df['avg_pretest_score'] >= 0.6, # Average score 60%+\n",
    "        'active_submission': df['total_submissions'] >= 1,  # Submitted at least 1 project\n",
    "        'high_engagement': df['engagement_score'] >= 0.7   # Overall engagement 70%+\n",
    "    }\n",
    "    \n",
    "    # Calculate completion score\n",
    "    df['completion_score'] = (\n",
    "        conditions['high_attendance'].astype(int) * 0.35 +      # Attendance weight\n",
    "        conditions['reached_advanced'].astype(int) * 0.25 +     # Progress weight  \n",
    "        conditions['good_performance'].astype(int) * 0.2 +      # Performance weight\n",
    "        conditions['active_submission'].astype(int) * 0.1 +     # Submission weight\n",
    "        conditions['high_engagement'].astype(int) * 0.1         # Engagement weight\n",
    "    )\n",
    "    \n",
    "    # Create binary labels\n",
    "    GRADUATION_THRESHOLD = 0.6  # Need 60% overall score to graduate\n",
    "    df['graduated_rule'] = (df['completion_score'] >= GRADUATION_THRESHOLD).astype(int)\n",
    "    \n",
    "    # Show criteria breakdown\n",
    "    print(\"Graduation Criteria:\")\n",
    "    for criterion, condition in conditions.items():\n",
    "        count = condition.sum()\n",
    "        pct = count / len(df) * 100\n",
    "        print(f\"  {criterion}: {count} participants ({pct:.1f}%)\")\n",
    "    \n",
    "    graduate_count = df['graduated_rule'].sum()\n",
    "    print(f\"\\nüéì Rule-based graduation rate: {graduate_count}/{len(df)} ({graduate_count/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1306f1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# METHOD 2: CLUSTERING-BASED LABELING  \n",
    "# ============================================================================\n",
    "\n",
    "def create_cluster_based_labels(df):\n",
    "    print(\"\\nüîç Method 2: Clustering-Based Labeling\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Prepare features for clustering\n",
    "    cluster_features = [\n",
    "        'attendance_rate', 'avg_pretest_score', 'total_submissions', \n",
    "        'engagement_score', 'highest_meeting'\n",
    "    ]\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(df[cluster_features])\n",
    "    \n",
    "    # Apply K-means clustering (k=3: low, medium, high performers)\n",
    "    kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "    df['cluster'] = kmeans.fit_predict(X_scaled)\n",
    "    \n",
    "    # Analyze clusters to identify high performers\n",
    "    cluster_analysis = df.groupby('cluster')[cluster_features].mean().round(3)\n",
    "    print(\"Cluster Analysis:\")\n",
    "    print(cluster_analysis)\n",
    "    \n",
    "    # Identify the \"high performer\" cluster (highest attendance + performance)\n",
    "    cluster_scores = cluster_analysis['attendance_rate'] + cluster_analysis['avg_pretest_score']\n",
    "    high_performer_cluster = cluster_scores.idxmax()\n",
    "    \n",
    "    # Create binary labels (high performer cluster = graduated)\n",
    "    df['graduated_cluster'] = (df['cluster'] == high_performer_cluster).astype(int)\n",
    "    \n",
    "    cluster_counts = df['cluster'].value_counts().sort_index()\n",
    "    print(f\"\\nCluster distribution:\")\n",
    "    for cluster, count in cluster_counts.items():\n",
    "        pct = count / len(df) * 100\n",
    "        status = \"HIGH PERFORMER\" if cluster == high_performer_cluster else \"REGULAR\"\n",
    "        print(f\"  Cluster {cluster}: {count} participants ({pct:.1f}%) - {status}\")\n",
    "    \n",
    "    graduate_count = df['graduated_cluster'].sum()\n",
    "    print(f\"\\nüéì Cluster-based graduation rate: {graduate_count}/{len(df)} ({graduate_count/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d36c3021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã Method 1: Rule-Based Labeling\n",
      "----------------------------------------\n",
      "Graduation Criteria:\n",
      "  high_attendance: 320 participants (58.3%)\n",
      "  reached_advanced: 465 participants (84.7%)\n",
      "  good_performance: 527 participants (96.0%)\n",
      "  active_submission: 549 participants (100.0%)\n",
      "  high_engagement: 518 participants (94.4%)\n",
      "\n",
      "üéì Rule-based graduation rate: 436/549 (79.4%)\n",
      "\n",
      "üîç Method 2: Clustering-Based Labeling\n",
      "----------------------------------------\n",
      "Cluster Analysis:\n",
      "         attendance_rate  avg_pretest_score  total_submissions  \\\n",
      "cluster                                                          \n",
      "0                  0.909              0.725              1.945   \n",
      "1                  0.698              0.781              1.975   \n",
      "2                  0.000              0.784              1.828   \n",
      "\n",
      "         engagement_score  highest_meeting  \n",
      "cluster                                     \n",
      "0                   0.906           27.326  \n",
      "1                   0.779           21.042  \n",
      "2                   0.368           24.000  \n",
      "\n",
      "Cluster distribution:\n",
      "  Cluster 0: 236 participants (43.0%) - HIGH PERFORMER\n",
      "  Cluster 1: 284 participants (51.7%) - REGULAR\n",
      "  Cluster 2: 29 participants (5.3%) - REGULAR\n",
      "\n",
      "üéì Cluster-based graduation rate: 236/549 (43.0%)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# EXECUTE TARGET CREATION\n",
    "# ============================================================================\n",
    "\n",
    "# Create labels using both methods\n",
    "target_df = create_rule_based_labels(target_df)\n",
    "target_df = create_cluster_based_labels(target_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "053f4c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç LABEL VALIDATION\n",
      "==================================================\n",
      "Agreement between methods: 349/549 (63.6%)\n",
      "\n",
      "Cross-tabulation:\n",
      "graduated_cluster    0    1  All\n",
      "graduated_rule                  \n",
      "0                  113    0  113\n",
      "1                  200  236  436\n",
      "All                313  236  549\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# LABEL VALIDATION & COMPARISON\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüîç LABEL VALIDATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Compare the two labeling methods\n",
    "agreement = (target_df['graduated_rule'] == target_df['graduated_cluster']).sum()\n",
    "agreement_rate = agreement / len(target_df) * 100\n",
    "\n",
    "print(f\"Agreement between methods: {agreement}/{len(target_df)} ({agreement_rate:.1f}%)\")\n",
    "\n",
    "# Cross-tabulation\n",
    "crosstab = pd.crosstab(\n",
    "    target_df['graduated_rule'], \n",
    "    target_df['graduated_cluster'], \n",
    "    margins=True\n",
    ")\n",
    "print(f\"\\nCross-tabulation:\")\n",
    "print(crosstab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "725d9a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ FINAL TARGET SELECTION\n",
      "------------------------------\n",
      "Final graduation rate: 436/549 (79.4%)\n",
      "\n",
      "Final Target Distribution:\n",
      "  Graduated (1): 436 participants\n",
      "  Not Graduated (0): 113 participants\n",
      "‚ö†Ô∏è  Class imbalance detected! Consider SMOTE for modeling.\n",
      "\n",
      "üéâ FINAL DATASET READY!\n",
      "Shape: (549, 21)\n",
      "Features: 20\n",
      "Target column: 'graduated_final'\n",
      "\n",
      "üìä Final Dataset Sample:\n",
      "                                     id  attendance_rate  avg_pretest_score  \\\n",
      "0  366c8261-243e-4eab-9695-6df81979597a            0.600              0.800   \n",
      "1  84d29b44-26c6-4b05-8a67-31831d35be32            0.933              0.783   \n",
      "2  e0766991-32fc-4294-b1e2-a0dff52c64f2            0.767              0.767   \n",
      "3  a59fa924-4733-471c-8754-f6595cd0e6f1            0.900              0.683   \n",
      "4  ab9d4c1f-1773-4f12-88e1-ecd78f51e309            1.000              0.867   \n",
      "5  f29b1b86-ab96-4876-889d-70b5955a01c7            0.900              0.600   \n",
      "6  e62e4b0c-e929-48f4-ad21-f172df57e747            0.767              0.833   \n",
      "7  4073acaa-d216-4e04-8729-bfadada4d095            0.667              0.617   \n",
      "8  28c21980-3720-4511-bec7-cc2e6275750a            0.933              0.767   \n",
      "9  6f2f152e-fe85-4611-857a-528266761927            0.667              0.750   \n",
      "\n",
      "   total_submissions  graduated_final  \n",
      "0                2.0                0  \n",
      "1                2.0                1  \n",
      "2                2.0                1  \n",
      "3                2.0                1  \n",
      "4                2.0                1  \n",
      "5                2.0                1  \n",
      "6                2.0                1  \n",
      "7                2.0                1  \n",
      "8                2.0                1  \n",
      "9                2.0                1  \n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# FINAL TARGET SELECTION\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\nüéØ FINAL TARGET SELECTION\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Use ensemble approach: agree on both methods OR high completion score\n",
    "target_df['graduated_final'] = (\n",
    "    (target_df['graduated_rule'] == 1) & \n",
    "    (target_df['graduated_cluster'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# For cases where methods disagree, use completion score as tiebreaker\n",
    "disagreement_mask = target_df['graduated_rule'] != target_df['graduated_cluster']\n",
    "high_score_mask = target_df['completion_score'] >= 0.65\n",
    "\n",
    "target_df.loc[disagreement_mask & high_score_mask, 'graduated_final'] = 1\n",
    "\n",
    "final_graduate_count = target_df['graduated_final'].sum()\n",
    "final_rate = final_graduate_count / len(target_df) * 100\n",
    "\n",
    "print(f\"Final graduation rate: {final_graduate_count}/{len(target_df)} ({final_rate:.1f}%)\")\n",
    "\n",
    "# Show final target distribution\n",
    "print(f\"\\nFinal Target Distribution:\")\n",
    "print(f\"  Graduated (1): {final_graduate_count} participants\")\n",
    "print(f\"  Not Graduated (0): {len(target_df) - final_graduate_count} participants\")\n",
    "\n",
    "# Class balance check\n",
    "if final_rate < 30 or final_rate > 70:\n",
    "    print(f\"‚ö†Ô∏è  Class imbalance detected! Consider SMOTE for modeling.\")\n",
    "else:\n",
    "    print(f\"‚úÖ Reasonable class balance for modeling.\")\n",
    "\n",
    "# Merge final target back to feature matrix\n",
    "final_features_with_target = final_features.merge(\n",
    "    target_df[['id', 'graduated_final', 'completion_score']], \n",
    "    on='id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"\\nüéâ FINAL DATASET READY!\")\n",
    "print(f\"Shape: {final_features_with_target.shape}\")\n",
    "print(f\"Features: {final_features_with_target.shape[1] - 1}\")  # -1 for target\n",
    "print(f\"Target column: 'graduated_final'\")\n",
    "\n",
    "# Save the final dataset\n",
    "# final_features_with_target.to_csv('bootcamp_final_dataset.csv', index=False)\n",
    "# print(f\"üíæ Dataset saved as 'bootcamp_final_dataset.csv'\")\n",
    "\n",
    "# Show sample of final dataset\n",
    "print(f\"\\nüìä Final Dataset Sample:\")\n",
    "sample_cols = ['id', 'attendance_rate', 'avg_pretest_score', 'total_submissions', 'graduated_final']\n",
    "print(final_features_with_target[sample_cols].head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
